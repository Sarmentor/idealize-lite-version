twitterdf <- data.frame(text=text, stringsAsFactors = FALSE)
twitterdf$text <- sapply(twitterdf$text,function(row) iconv(row, "latin1", "ASCII", sub=""))#Removing emoticons from tweets
twitterCorpus <- Corpus(VectorSource(twitterdf$text)) #Creating Corpus
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x)) #function to replace a pattern to white space using regex
twitterCorpus <- tm_map(twitterCorpus, toSpace, "(RT|via)((?:\\b\\W*@\\w+)+)") #match rt or via
twitterCorpus <- tm_map(twitterCorpus, toSpace, "@\\w+") #match @
twitterCorpus <- tm_map(twitterCorpus, toSpace, "[ \t]{2,}") #match tabs
twitterCorpus <- tm_map(twitterCorpus, toSpace, "[ |\n]{1,}") #match new lines
twitterCorpus <- tm_map(twitterCorpus, toSpace, "^ ") #match white space at begenning
twitterCorpus <- tm_map(twitterCorpus, toSpace, " $") #match white space at the end
twitterCorpus <- tm_map(twitterCorpus, PlainTextDocument)
twitterCorpus <- tm_map(twitterCorpus, removeNumbers)
twitterCorpus <- tm_map(twitterCorpus, removePunctuation)
twitterCorpus <- tm_map(twitterCorpus, toSpace, "http[[:alnum:]]*") #remove url from tweets
twitterCorpus <- tm_map(twitterCorpus,removeWords,stopwords("en"))
twitterCorpus <- tm_map(twitterCorpus, content_transformer(tolower))
return(twitterCorpus)
}
#global word count
freqPlot(all.text.user$text) #creating frequency plots
#global word cloud
makeWordcloud(all.text.user$text) #creating wordcloud
#fazer cosine similarity por utilizador
#fazer cluster ou rede de similaridade
hCluster(costable.dtm.text) #hierarchical clustering
costable.dtm.text
?hcluster
??hcluster
#fazer cosine similarity por utilizador
#fazer cluster ou rede de similaridade
hClust(costable.dtm.text) #hierarchical clustering
#fazer cosine similarity por utilizador
#fazer cluster ou rede de similaridade
hCluster(costable.dtm.text) #hierarchical clustering
traceback()
#fazer cosine similarity por utilizador
#fazer cluster ou rede de similaridade
hCluster.users(costable.dtm.text) #hierarchical clustering
#Clustering
hCluster.users<-function (sim.matrix){ #hierarchical clustering
fit <- hclust(sim.matrix, method="ward.D") #clustering terms
plot(fit)
rect.hclust(fit, k=5) #cutting the tree into 5 clusters
(groups <- cutree(fit, k=5))
}
#fazer cosine similarity por utilizador
#fazer cluster ou rede de similaridade
hCluster.users(costable.dtm.text) #hierarchical clustering
#fazer cosine similarity por utilizador
#fazer cluster ou rede de similaridade
hCluster.users(costable.dtm.text) #hierarchical clustering
#fazer cosine similarity por utilizador
#fazer cluster ou rede de similaridade
hCluster.users(as.matrix(costable.dtm.text)) #hierarchical clustering
traceb ack()
traceback()
hclust(costable.dtm.text, method="ward.D")
?hclust
hclust(as.dist(costable.dtm.text), method="ward.D")
#fazer cosine similarity por utilizador
#fazer cluster ou rede de similaridade
hCluster.users(as.dist(costable.dtm.text)) #hierarchical clustering
#fazer cosine similarity por utilizador
#fazer cluster ou rede de similaridade
names(hCluster.users(as.dist(costable.dtm.text))) #hierarchical clustering
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R', encoding = 'UTF-8')
fit
fit
names(fit)
fit$order
fit$labels
fit$height
fit$merge
fit
groups
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R', encoding = 'UTF-8')
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R', encoding = 'UTF-8')
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R', encoding = 'UTF-8')
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R', encoding = 'UTF-8')
?dialogWindow
??dialogWindow
??dialog
shiny::runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
traceback()
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Wikipedia Text-to-Voice/Shiny')
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R', encoding = 'UTF-8')
clust.groups
i=1
names(clust.groups[which(clust.groups==i)])
users.clust <- names(clust.groups[which(clust.groups==i)])
paste(all.text.user[which(all.text.user$doc_id %in% users.clust),"text"])
text.clust <- paste(all.text.user[which(all.text.user$doc_id %in% users.clust),"text"])
tSentimen(text.clust)
tSentimen(paste(text.clust, collapse=" "))
paste(text.clust, collapse=" ")
makeCorpus(text.clust)
unlist(sapply(twicorpus, `[`, "content"))
twicorpus<-makeCorpus(text.clust)
unlist(sapply(twicorpus, `[`, "content"))
names(twicorpus)
twicorpus[[1]]
twicorpus[[1]]$content
twicorpus[[]]$content
twicorpus[[1:2]]$content
twicorpus[[1]]$content
twicorpus[[2]]$content
unlist(twicorpus[[]])$content
unlist(twicorpus)$content
unlist(twicorpus)
class(unlist(twicorpus))
lapply(twicorpus, FUN=function(x){x$content})
lapply(twicorpus, FUN=function(x){x$"content"})
?lapply
twicorpus$content
data.frame(text=twicorpus$content, stringsAsFactors=F)
nrows(data.frame(text=twicorpus$content, stringsAsFactors=F))
nrow(data.frame(text=twicorpus$content, stringsAsFactors=F))
ncol(data.frame(text=twicorpus$content, stringsAsFactors=F))
dataframe<-data.frame(text=twicorpus$content, stringsAsFactors=F)
poldat <- with(dataframe, polarity(text))
names(dataframe)
poldat <- with(dataframe, polarity("text"))
poldat <- with(dataframe, polarity(paste(twicorpus$content,collapse = " ")))
poldat <- polarity(paste(twicorpus$content,collapse = " "))
polarity(paste(twicorpus$content,collapse = " "))
traceback()
`[[.qdap_hash` <- `[[.data.frame`
poldat <- with(dataframe, polarity(text))
tSentimen(text.clust)
text.clust
tSentimen(text.clust)$stan.mean.polarit
tSentimen(text.clust)$stan.mean.polarity
tSentimen(text.clust)["stan.mean.polarity"]
names(tSentimen(text.clust))
tSentimen(text.clust)$all
tSentimen(text.clust)$group
tSentimen(text.clust)$group$stan.mean.polarity
?polarity
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R', encoding = 'UTF-8')
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R', encoding = 'UTF-8')
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R', encoding = 'UTF-8')
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R', encoding = 'UTF-8')
??rtweet
# Set up authentication
Auth<-create_token(consumer_key=APIKey, consumer_secret=APISecret,access_token = AccessToken, access_secret =AccessTokenSecret)
Auth
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R', encoding = 'UTF-8')
traceback()
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R', encoding = 'UTF-8')
remove.packages("twitteR")
library(twitteR)
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R', encoding = 'UTF-8')
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R', encoding = 'UTF-8')
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R', encoding = 'UTF-8')
remove.packages(qdap)
remove.packages("qdap")
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R', encoding = 'UTF-8')
install.packages("qdap")
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R', encoding = 'UTF-8')
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R')
traceback()
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R')
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R')
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Crypto-News-Sentiment.R')
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Bitcoins Stream/Mine/Finance-Twitter-News-Sentiment-Per-Users-Groups.R')
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Fundamental Project/Freelancer Code/main_LV.R')
install.packages("quantmod")
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Fundamental Project/Freelancer Code/main_LV.R')
install.packages("tseries")
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Fundamental Project/Freelancer Code/main_LV.R')
install.packages("caret")
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Fundamental Project/Freelancer Code/main_LV.R')
install.packages("ipred")
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Fundamental Project/Freelancer Code/main_LV.R')
install.packages("rio")
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Fundamental Project/Freelancer Code/main_LV.R')
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Fundamental Project/Freelancer Code/main_LV.R')
install.packages(c("backports", "BH", "callr", "clipr", "colorspace", "curl", "data.table", "dbplyr", "ddalpha", "dynlm", "e1071", "flextable", "forecast", "git2r", "httpuv", "hunspell", "lme4", "openssl", "pdftools", "pillar", "plm", "prabclus", "psych", "purrr", "quanteda", "quantreg", "RcppArmadillo", "RcppParallel", "readr", "readxl", "rlang", "rstudioapi", "slam", "SnowballC", "spacyr", "striprtf", "tibble", "tinytex", "topicmodels", "udpipe", "xgboost"))
install.packages(c("backports", "BH", "callr", "clipr", "colorspace", "curl", "data.table", "dbplyr", "ddalpha", "dynlm", "e1071", "flextable", "forecast", "git2r", "httpuv", "hunspell", "lme4", "openssl", "pdftools", "pillar", "plm", "prabclus", "psych", "purrr", "quanteda", "quantreg", "RcppArmadillo", "RcppParallel", "readr", "readxl", "rlang", "rstudioapi", "slam", "SnowballC", "spacyr", "striprtf", "tibble", "tinytex", "topicmodels", "udpipe", "xgboost"))
install.packages(c("backports", "BH", "callr", "clipr", "colorspace", "curl", "data.table", "dbplyr", "ddalpha", "dynlm", "e1071", "flextable", "forecast", "git2r", "httpuv", "hunspell", "lme4", "openssl", "pdftools", "pillar", "plm", "prabclus", "psych", "purrr", "quanteda", "quantreg", "RcppArmadillo", "RcppParallel", "readr", "readxl", "rlang", "rstudioapi", "slam", "SnowballC", "spacyr", "striprtf", "tibble", "tinytex", "topicmodels", "udpipe", "xgboost"))
install.packages(c("backports", "BH", "callr", "clipr", "colorspace", "curl", "data.table", "dbplyr", "ddalpha", "dynlm", "e1071", "flextable", "forecast", "git2r", "httpuv", "hunspell", "lme4", "openssl", "pdftools", "pillar", "plm", "prabclus", "psych", "purrr", "quanteda", "quantreg", "RcppArmadillo", "RcppParallel", "readr", "readxl", "rlang", "rstudioapi", "slam", "SnowballC", "spacyr", "striprtf", "tibble", "tinytex", "topicmodels", "udpipe", "xgboost"))
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Fundamental Project/Freelancer Code/main_LV.R')
install.packages("tibble")
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Fundamental Project/Freelancer Code/main_LV.R')
install.packages("purrr")
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Fundamental Project/Freelancer Code/main_LV.R')
install.packages("colorspace")
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Fundamental Project/Freelancer Code/main_LV.R')
install.packages("data.table")
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Fundamental Project/Freelancer Code/main_LV.R')
install.packages("xgboost")
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Fundamental Project/Freelancer Code/main_LV.R')
install.packages("ps")
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Fundamental Project/Freelancer Code/main_LV.R')
url
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Fundamental Project/Freelancer Code/main_LV.R')
traceback()
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Fundamental Project/Freelancer Code/main_LV.R')
source('C:/Users/Rui Sarmento/Dropbox/Projectos/Fundamental Project/Freelancer Code/main_LV.R')
anova(lasso_mod, xgb_mod)
anova(xgb_mod, model)
k = ncol(X_train)
## create your model,and add layers
model <- keras_model_sequential()
model %>%
layer_dense(units = 60, activation = 'relu', input_shape = k) %>%
layer_dropout(rate = 0.2) %>%
layer_dense(units = 50, activation = 'relu') %>%
layer_dropout(rate = 0.2) %>%
layer_dense(units = 1, activation = 'linear')
summary(model)
model %>% compile(
optimizer = 'rmsprop',
loss = 'mse',
metrics = 'mse'
)
###########################
# Step 2: Train the model #
###########################
model %>% fit(X_train, y_train, epochs=100, batch_size=28, validation_split = 0.1)
################################
# Step 2: Plot the predictions #
################################
pred <- model %>% predict(X_test, batch_size = 28)
print("Next Seven Days Forecast using Neural Network Regression will be : ")
print(pred)
#################################
# Compare the Models with Anova #
#################################
anova(lasso_mod, xgb_mod)
anova(xgb_mod, model)
?anova
model
xgb_mod
lasso_mod
class(lasso_mod)
class(xgb_mod)
class(model)
library(rPython)
install.packages("rPython")
install.packages("Rtools")
install.packages("devtools")
install.packages("Rtools")
library(Rtools)
library(Rtools)
library(Rtools)
library(devtools)
library(rPython)
source('C:/Users/Rui Sarmento/Dropbox/Educação/Doutoramento/Tese/Dyncomm R Package/DynComm-R-package/R-CRAN/R/TILES.R')
?python.load
source('C:/Users/Rui Sarmento/Dropbox/Educação/Doutoramento/Tese/Dyncomm R Package/DynComm-R-package/R-CRAN/R/TILES.R')
source('C:/Users/Rui Sarmento/Dropbox/Educação/Doutoramento/Tese/Dyncomm R Package/DynComm-R-package/R-CRAN/R/TILES.R')
source('C:/Users/Rui Sarmento/Dropbox/Educação/Doutoramento/Tese/Dyncomm R Package/DynComm-R-package/R-CRAN/R/TILES.R')
source('C:/Users/Rui Sarmento/Dropbox/Educação/Doutoramento/Tese/Dyncomm R Package/DynComm-R-package/R-CRAN/R/TILES.R')
?py_install
?source_python
inf
?inf
infinity
1/0
Inf
import("networkx")
?nx.Graph()
Caca <- 2
caca <- 3
Caca
caca
shiny::runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
?as.table
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
shiny::runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
?plot
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
plot(trends.table[1:nrow(trends.table),])
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
plot(trends.table[1:nrow(trends.table),])
trends.table
plot(trends.table)
plot(trends.table[1,])
cite(IncRcpa)
cite(Rcpa)
cite(incRcpa)
cite(onlinePCA)
cite("onlinePCA")
library("onlinePCA")
cite(onlinePCA)
cite("onlinePCA")
library("onlinePCA")
cite(onlinePCA)
cite("onlinePCA")
library(gtrendsR)
cite(gtrendsR)
cite("gtrendsR")
shiny::runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
View(trends.table)
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
keys.list[ngd.i]
input$Region
NGD
list
results <- list(NGD=NGD,
x=c(x, freq.locality),
y=c(x, freq.capital),
xy=c(paste("Local + Capital"), freq.loccap))
results
as.data.frame(results)
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
keys
key
sub_code
input$Region
local
gtrends(keyword = key, geo= c(strsplit(sub_code[1], split="-")[[1]][2],strsplit(sub_code[1], split="-")[[1]][1]), time = "today 12-m",gprop = c("web"), category = 0, hl = "en-US", low_search_volume = FALSE,cookie_url = "http://trends.google.com/Cookies/NID")$interest_over_time$hits
length(gtrends(keyword = key, geo= c(strsplit(sub_code[1], split="-")[[1]][2],strsplit(sub_code[1], split="-")[[1]][1]), time = "today 12-m",gprop = c("web"), category = 0, hl = "en-US", low_search_volume = FALSE,cookie_url = "http://trends.google.com/Cookies/NID")$interest_over_time$hits)
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
?tabPanel
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
ngd
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize/Shiny')
source('C:/Users/Rui Sarmento/Dropbox/Educação/Doutoramento/Tese/Bipartite Incremental Similarity/CZECH-DATA-FILTER.R')
setwd("C:/Users/Rui Sarmento/Dropbox/Educação/Doutoramento/Tese/Bipartite Incremental Similarity")
source('C:/Users/Rui Sarmento/Dropbox/Educação/Doutoramento/Tese/Bipartite Incremental Similarity/CZECH-DATA-FILTER.R')
setwd("C:/Users/Rui Sarmento/Dropbox/Educação/Doutoramento/Tese/Bipartite Incremental Similarity")
source('C:/Users/Rui Sarmento/Dropbox/Educação/Doutoramento/Tese/Bipartite Incremental Similarity/CZECH-DATA-FILTER.R')
setwd("C:/Users/Rui Sarmento/Dropbox/Educação/Doutoramento/Tese/Bipartite Incremental Similarity")
source('C:/Users/Rui Sarmento/Dropbox/Educação/Doutoramento/Tese/Bipartite Incremental Similarity/CZECH-DATA-FILTER.R')
source('C:/Users/Rui Sarmento/Dropbox/Educação/Doutoramento/Tese/Bipartite Incremental Similarity/CZECH-DATA-FILTER.R')
setwd("C:/Users/Rui Sarmento/Dropbox/Educação/Doutoramento/Tese/Bipartite Incremental Similarity")
?getForm
shiny::runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
# User interface ----
ui <- fluidPage(
titlePanel("Idealize"),
sidebarPanel(
helpText("Idealize Idea Strength by Region and Country"),
selectInput("Country",
label = "Choose a country to display",
choices = c("ENGLAND","USA"),
selected = NULL)
,
actionButton("start", "GO!"),
helpText("Idealize Extracted Keywords"),
textOutput("keys")
),
mainPanel(
tableOutput("ideatable"),
fluidRow(
column(width = 4,
box(
title = "Box title", width = NULL, status = "primary",
div(style = 'overflow-x: scroll', tableOutput('trendslocal'))
))),
fluidRow(
column(width = 4,
box(
title = "Box title", width = NULL, status = "primary",
div(style = 'overflow-x: scroll', tableOutput('trendscapital'))
)))
)
)
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
cat(keys.list[,"keywords"], sep = "\n")
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
paste(keys.list[,"keywords"], sep = "\n")
paste(keys.list[,"keywords"], collapse =  = "\n")
paste(keys.list[,"keywords"], collapse ="\n")
paste(paste(keys.list[,"keywords"], collapse ="\n"))
paste(paste(keys.list[,"keywords"], collapse ="\\n"))
cat(paste(keys.list[,"keywords"], collapse ="\\n"))
cat(paste(keys.list[,"keywords"], collapse =" \n "))
cat(paste(keys.list[,"keywords"], collapse ="\n "))
cat(paste(keys.list[,"keywords"], collapse ="\n"))
as.character(paste(keys.list[,"keywords"], collapse ="\n"))
paste0(keys.list[,"keywords"], collapse ="\n")
print(keys.list[,"keywords"], collapse ="\n")
print(cat(keys.list[,"keywords"], collapse ="\n"))
print(cat(keys.list[,"keywords"]))
paste0(keys.list[,"keywords"], collapse ="\n")
cat(paste(keys.list[,"keywords"], collapse ="\n"))
print(cat(paste(keys.list[,"keywords"], collapse ="\n")))
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
sub_code
countries[which(countries[,"country_code"]==country
),"sub_code"]
country
country
countries[which(countries[,"country_code"]=="GB" ),]
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
sub_code
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
geo.vec
geo.vec <- c(strsplit(sub_code[1], split="-")[[1]][2],strsplit(sub_code[1], split="-")[[1]][1])
geo.vec
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
geo.vec
geo.vec[2]="UK"
geo.vec
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
geo.vec
geo.vec[2]="EN"
geo.vec
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
geo.vec
country
local
sub_code
country="US"
sub_code <- as.character(countries[which(countries[,"country_code"]==country & countries[,"name"]==paste(toupper(local))),"sub_code"])
sub_code
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
geo.vec
geo.vec
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
geo.vec
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/Shiny')
head(gtrends(c("NHL", "NFL"), geo = c("CA", "US"))$interest_over_time)
gtrends(keyword="obama",geo="US-AL-630")
gtrends(keyword="obama",geo="US")
gtrends(keyword="obama",geo="UK")
gtrends(keyword="obama",geo="GB")
shiny::runApp('C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/idealize-lite-version/Shiny')
setwd("C:/Users/Rui Sarmento/Dropbox/Projectos/Idealize Shiny/idealize - Published/idealize-lite-version/Shiny")
runApp()
df.cities[which(df.cities[,country=="GB"]),"cities"]
df.cities
df.cities[which(df.cities[,"country"]=="GB"),"cities"]
runApp()
runApp()
geo.vec
gtrends(keyword = keys[key], geo= geo.vec, time = "today 12-m",gprop = c("web"), category = 0, hl = "en", low_search_volume = FALSE,cookie_url = "http://trends.google.com/Cookies/NID")$interest_over_time$hits
keys
gtrends(keyword = "isolate education", geo= geo.vec, time = "today 12-m",gprop = c("web"), category = 0, hl = "en", low_search_volume = FALSE,cookie_url = "http://trends.google.com/Cookies/NID")$interest_over_time$hits
geo.vec
geo.vec[2]="UK"
gtrends(keyword = "isolate education", geo= geo.vec, time = "today 12-m",gprop = c("web"), category = 0, hl = "en", low_search_volume = FALSE,cookie_url = "http://trends.google.com/Cookies/NID")$interest_over_time$hits
data(countries)
countries
unique(any(countries[,"country_code"]=="GB"))
unique(any(countries[,"country_code"]=="US"))
unique(any(countries[,"country_code"]=="PT"))
unique(any(countries[,"country_code"]=="ET"))
unique(any(countries[,"country_code"]=="EZ"))
countries[which(countries[,"country_code"]=="GB"),]
gtrends(keyword="obama",geo="UK")
gtrends(keyword="obama",geo="GB")
gtrends(keyword="obama",geo="US")
runApp()
runApp()
eval(paste(paste(ind.var," ~ "),paste(dep.vars,sep= " + ")))
ind.var <- "caca"
dep.vars <- c("cococ","cocoa","coco")
eval(paste(paste(ind.var," ~ "),paste(dep.vars,sep= " + ")))
eval(paste(paste(ind.var," ~ "),paste(dep.vars,collapse= " + ")))
library(shiny); runApp('app-GITHUB.R')
runApp('app-GITHUB.R')
runApp('app-GITHUB.R')
runApp('app-GITHUB.R')
